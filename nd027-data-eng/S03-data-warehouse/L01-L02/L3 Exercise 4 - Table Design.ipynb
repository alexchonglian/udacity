{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Optimizing Redshift Table Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "KEY=config.get('AWS','key')\n",
    "SECRET= config.get('AWS','secret')\n",
    "\n",
    "DWH_DB= config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER= config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD= config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT = config.get(\"DWH\",\"DWH_PORT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Get the params of the created redshift cluster \n",
    "- We need:\n",
    "    - The redshift cluster <font color='red'>endpoint</font>\n",
    "    - The <font color='red'>IAM role ARN</font> that give access to Redshift to read from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN THE REDSHIFT ENDPOINT HERE\n",
    "# e.g. DWH_ENDPOINT=\"redshift-cluster-1.csmamz5zxmle.us-west-2.redshift.amazonaws.com\" \n",
    "DWH_ENDPOINT=\"dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com\"\n",
    "\n",
    "#FILL IN THE IAM ROLE ARN you got in step 2.2 of the previous exercise\n",
    "#e.g DWH_ROLE_ARN=\"arn:aws:iam::988332130976:role/dwhRole\"\n",
    "DWH_ROLE_ARN=\"arn:aws:iam::769590699532:role/dwhRole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Connect to the Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://dwhuser:Passw0rd@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 3: Create Tables\n",
    "- We are going to use a benchmarking data set common for benchmarking star schemas in data warehouses.\n",
    "- The data is pre-loaded in a public bucket on the `us-west-2` region\n",
    "- Our examples will be based on the Amazon Redshfit tutorial but in a scripted environment in our workspace.\n",
    "\n",
    "![afa](https://docs.aws.amazon.com/redshift/latest/dg/images/tutorial-optimize-tables-ssb-data-model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create tables (no distribution strategy) in the `nodist` schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "CREATE SCHEMA IF NOT EXISTS nodist;\n",
    "SET search_path TO nodist;\n",
    "\n",
    "DROP TABLE IF EXISTS part cascade;\n",
    "DROP TABLE IF EXISTS supplier;\n",
    "DROP TABLE IF EXISTS supplier;\n",
    "DROP TABLE IF EXISTS customer;\n",
    "DROP TABLE IF EXISTS dwdate;\n",
    "DROP TABLE IF EXISTS lineorder;\n",
    "\n",
    "CREATE TABLE part \n",
    "(\n",
    "  p_partkey     integer not null,\n",
    "  p_name        varchar(22) not null,\n",
    "  p_mfgr        varchar(6) not null,\n",
    "  p_category    varchar(7) not null,\n",
    "  p_brand1      varchar(9) not null,\n",
    "  p_color       varchar(11) not null,\n",
    "  p_type        varchar(25) not null,\n",
    "  p_size        integer not null,\n",
    "  p_container   varchar(10) not null\n",
    ");\n",
    "\n",
    "CREATE TABLE supplier \n",
    "(\n",
    "  s_suppkey     integer not null,\n",
    "  s_name        varchar(25) not null,\n",
    "  s_address     varchar(25) not null,\n",
    "  s_city        varchar(10) not null,\n",
    "  s_nation      varchar(15) not null,\n",
    "  s_region      varchar(12) not null,\n",
    "  s_phone       varchar(15) not null\n",
    ");\n",
    "\n",
    "CREATE TABLE customer \n",
    "(\n",
    "  c_custkey     integer not null,\n",
    "  c_name        varchar(25) not null,\n",
    "  c_address     varchar(25) not null,\n",
    "  c_city        varchar(10) not null,\n",
    "  c_nation      varchar(15) not null,\n",
    "  c_region      varchar(12) not null,\n",
    "  c_phone       varchar(15) not null,\n",
    "  c_mktsegment  varchar(10) not null\n",
    ");\n",
    "\n",
    "CREATE TABLE dwdate \n",
    "(\n",
    "  d_datekey            integer not null,\n",
    "  d_date               varchar(19) not null,\n",
    "  d_dayofweek          varchar(10) not null,\n",
    "  d_month              varchar(10) not null,\n",
    "  d_year               integer not null,\n",
    "  d_yearmonthnum       integer not null,\n",
    "  d_yearmonth          varchar(8) not null,\n",
    "  d_daynuminweek       integer not null,\n",
    "  d_daynuminmonth      integer not null,\n",
    "  d_daynuminyear       integer not null,\n",
    "  d_monthnuminyear     integer not null,\n",
    "  d_weeknuminyear      integer not null,\n",
    "  d_sellingseason      varchar(13) not null,\n",
    "  d_lastdayinweekfl    varchar(1) not null,\n",
    "  d_lastdayinmonthfl   varchar(1) not null,\n",
    "  d_holidayfl          varchar(1) not null,\n",
    "  d_weekdayfl          varchar(1) not null\n",
    ");\n",
    "\n",
    "CREATE TABLE lineorder \n",
    "(\n",
    "  lo_orderkey          integer not null,\n",
    "  lo_linenumber        integer not null,\n",
    "  lo_custkey           integer not null,\n",
    "  lo_partkey           integer not null,\n",
    "  lo_suppkey           integer not null,\n",
    "  lo_orderdate         integer not null,\n",
    "  lo_orderpriority     varchar(15) not null,\n",
    "  lo_shippriority      varchar(1) not null,\n",
    "  lo_quantity          integer not null,\n",
    "  lo_extendedprice     integer not null,\n",
    "  lo_ordertotalprice   integer not null,\n",
    "  lo_discount          integer not null,\n",
    "  lo_revenue           integer not null,\n",
    "  lo_supplycost        integer not null,\n",
    "  lo_tax               integer not null,\n",
    "  lo_commitdate        integer not null,\n",
    "  lo_shipmode          varchar(10) not null\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create tables (with a distribution strategy) in the `dist` schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS dist;\n",
    "SET search_path TO dist;\n",
    "\n",
    "DROP TABLE IF EXISTS part cascade;\n",
    "DROP TABLE IF EXISTS supplier;\n",
    "DROP TABLE IF EXISTS supplier;\n",
    "DROP TABLE IF EXISTS customer;\n",
    "DROP TABLE IF EXISTS dwdate;\n",
    "DROP TABLE IF EXISTS lineorder;\n",
    "\n",
    "CREATE TABLE part\n",
    "(\n",
    "  p_partkey     integer not null  sortkey distkey,\n",
    "  p_name        varchar(22) not null,\n",
    "  p_mfgr        varchar(6) not null,\n",
    "  p_category    varchar(7) not null,\n",
    "  p_brand1      varchar(9) not null,\n",
    "  p_color       varchar(11) not null,\n",
    "  p_type        varchar(25) not null,\n",
    "  p_size        integer not null,\n",
    "  p_container   varchar(10) not null\n",
    ");\n",
    "\n",
    "CREATE TABLE supplier\n",
    "(\n",
    "  s_suppkey     integer  not null sortkey,\n",
    "  s_name        varchar(25) not null,\n",
    "  s_address     varchar(25) not null,\n",
    "  s_city        varchar(10) not null,\n",
    "  s_nation      varchar(15) not null,\n",
    "  s_region      varchar(12) not null,\n",
    "  s_phone       varchar(15) not null\n",
    ") diststyle all;\n",
    "\n",
    "CREATE TABLE customer\n",
    "(\n",
    "  c_custkey     integer  not null sortkey,\n",
    "  c_name        varchar(25) not null,\n",
    "  c_address     varchar(25) not null,\n",
    "  c_city        varchar(10) not null,\n",
    "  c_nation      varchar(15) not null,\n",
    "  c_region      varchar(12) not null,\n",
    "  c_phone       varchar(15) not null,\n",
    "  c_mktsegment  varchar(10) not null\n",
    ") diststyle all;\n",
    "\n",
    "CREATE TABLE dwdate\n",
    "(\n",
    "  d_datekey            integer not null sortkey,\n",
    "  d_date               varchar(19) not null,\n",
    "  d_dayofweek          varchar(10) not null,\n",
    "  d_month              varchar(10) not null,\n",
    "  d_year               integer not null,\n",
    "  d_yearmonthnum       integer not null,\n",
    "  d_yearmonth          varchar(8) not null,\n",
    "  d_daynuminweek       integer not null,\n",
    "  d_daynuminmonth      integer not null,\n",
    "  d_daynuminyear       integer not null,\n",
    "  d_monthnuminyear     integer not null,\n",
    "  d_weeknuminyear      integer not null,\n",
    "  d_sellingseason      varchar(13) not null,\n",
    "  d_lastdayinweekfl    varchar(1) not null,\n",
    "  d_lastdayinmonthfl   varchar(1) not null,\n",
    "  d_holidayfl          varchar(1) not null,\n",
    "  d_weekdayfl          varchar(1) not null\n",
    ") diststyle all;\n",
    "\n",
    "CREATE TABLE lineorder\n",
    "(\n",
    "  lo_orderkey          integer not null,\n",
    "  lo_linenumber        integer not null,\n",
    "  lo_custkey           integer not null,\n",
    "  lo_partkey           integer not null distkey,\n",
    "  lo_suppkey           integer not null,\n",
    "  lo_orderdate         integer not null sortkey,\n",
    "  lo_orderpriority     varchar(15) not null,\n",
    "  lo_shippriority      varchar(1) not null,\n",
    "  lo_quantity          integer not null,\n",
    "  lo_extendedprice     integer not null,\n",
    "  lo_ordertotalprice   integer not null,\n",
    "  lo_discount          integer not null,\n",
    "  lo_revenue           integer not null,\n",
    "  lo_supplycost        integer not null,\n",
    "  lo_tax               integer not null,\n",
    "  lo_commitdate        integer not null,\n",
    "  lo_shipmode          varchar(10) not null\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# STEP 4: Copying tables \n",
    "\n",
    "Our intent here is to run 5 COPY operations for the 5 tables respectively as show below.\n",
    "\n",
    "However, we want to do accomplish the following:\n",
    "- Make sure that the `DWH_ROLE_ARN` is substituted with the correct value in each query\n",
    "- Perform the data loading twice once for each schema (dist and nodist)\n",
    "- Collect timing statistics to compare the insertion times\n",
    "Thus, we have scripted the insertion as found below in the function `loadTables` which\n",
    "returns a pandas dataframe containing timing statistics for the copy operations\n",
    "\n",
    "```sql\n",
    "copy customer from 's3://awssampledbuswest2/ssbgz/customer' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy part from 's3://awssampledbuswest2/ssbgz/part' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "\n",
    "copy supplier from 's3://awssampledbuswest2/ssbgz/supplier' \n",
    "credentials 'aws_iam_role=<DWH_ROLE_ARN>'\n",
    "gzip region 'us-west-2';\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Automate  the copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTables(schema, tables):\n",
    "    loadTimes = []\n",
    "    SQL_SET_SCEMA = \"SET search_path TO {};\".format(schema)\n",
    "    %sql $SQL_SET_SCEMA\n",
    "    \n",
    "    for table in tables:\n",
    "        SQL_COPY = \"\"\"\n",
    "copy {} from 's3://awssampledbuswest2/ssbgz/{}' \n",
    "credentials 'aws_iam_role={}'\n",
    "gzip region 'us-west-2';\n",
    "        \"\"\".format(table,table, DWH_ROLE_ARN)\n",
    "\n",
    "        print(\"======= LOADING TABLE: ** {} ** IN SCHEMA ==> {} =======\".format(table, schema))\n",
    "        print(SQL_COPY)\n",
    "\n",
    "        t0 = time()\n",
    "        %sql $SQL_COPY\n",
    "        loadTime = time()-t0\n",
    "        loadTimes.append(loadTime)\n",
    "\n",
    "        print(\"=== DONE IN: {0:.2f} sec\\n\".format(loadTime))\n",
    "    return pd.DataFrame({\"table\":tables, \"loadtime_\"+schema:loadTimes}).set_index('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "======= LOADING TABLE: ** customer ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "copy customer from 's3://awssampledbuswest2/ssbgz/customer' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 11.46 sec\n",
      "\n",
      "======= LOADING TABLE: ** dwdate ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 0.84 sec\n",
      "\n",
      "======= LOADING TABLE: ** supplier ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "copy supplier from 's3://awssampledbuswest2/ssbgz/supplier' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 5.60 sec\n",
      "\n",
      "======= LOADING TABLE: ** part ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "copy part from 's3://awssampledbuswest2/ssbgz/part' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 3.19 sec\n",
      "\n",
      "======= LOADING TABLE: ** lineorder ** IN SCHEMA ==> nodist =======\n",
      "\n",
      "copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 486.79 sec\n",
      "\n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "======= LOADING TABLE: ** customer ** IN SCHEMA ==> dist =======\n",
      "\n",
      "copy customer from 's3://awssampledbuswest2/ssbgz/customer' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 13.63 sec\n",
      "\n",
      "======= LOADING TABLE: ** dwdate ** IN SCHEMA ==> dist =======\n",
      "\n",
      "copy dwdate from 's3://awssampledbuswest2/ssbgz/dwdate' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 0.91 sec\n",
      "\n",
      "======= LOADING TABLE: ** supplier ** IN SCHEMA ==> dist =======\n",
      "\n",
      "copy supplier from 's3://awssampledbuswest2/ssbgz/supplier' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 4.53 sec\n",
      "\n",
      "======= LOADING TABLE: ** part ** IN SCHEMA ==> dist =======\n",
      "\n",
      "copy part from 's3://awssampledbuswest2/ssbgz/part' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "Done.\n",
      "=== DONE IN: 2.42 sec\n",
      "\n",
      "======= LOADING TABLE: ** lineorder ** IN SCHEMA ==> dist =======\n",
      "\n",
      "copy lineorder from 's3://awssampledbuswest2/ssbgz/lineorder' \n",
      "credentials 'aws_iam_role=arn:aws:iam::769590699532:role/dwhRole'\n",
      "gzip region 'us-west-2';\n",
      "        \n",
      " * postgresql://dwhuser:***@dwhcluster.cnqie2ev0tzz.us-west-2.redshift.amazonaws.com:5439/dwh\n"
     ]
    }
   ],
   "source": [
    "#-- List of the tables to be loaded\n",
    "tables = [\"customer\",\"dwdate\",\"supplier\", \"part\", \"lineorder\"]\n",
    "\n",
    "#-- Insertion twice for each schema (WARNING!! EACH CAN TAKE MORE THAN 10 MINUTES!!!)\n",
    "nodistStats = loadTables(\"nodist\", tables)\n",
    "distStats = loadTables(\"dist\", tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Compare the load performance results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Plotting of the timing results\n",
    "stats = distStats.join(nodistStats)\n",
    "stats.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: Compare Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDim_SQL =\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select sum(lo_extendedprice*lo_discount) as revenue\n",
    "from lineorder, dwdate\n",
    "where lo_orderdate = d_datekey\n",
    "and d_year = 1997 \n",
    "and lo_discount between 1 and 3 \n",
    "and lo_quantity < 24;\n",
    "\"\"\"\n",
    "\n",
    "twoDim_SQL=\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select sum(lo_revenue), d_year, p_brand1\n",
    "from lineorder, dwdate, part, supplier\n",
    "where lo_orderdate = d_datekey\n",
    "and lo_partkey = p_partkey\n",
    "and lo_suppkey = s_suppkey\n",
    "and p_category = 'MFGR#12'\n",
    "and s_region = 'AMERICA'\n",
    "group by d_year, p_brand1\n",
    "\"\"\"\n",
    "\n",
    "drill_SQL = \"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select c_city, s_city, d_year, sum(lo_revenue) as revenue \n",
    "from customer, lineorder, supplier, dwdate\n",
    "where lo_custkey = c_custkey\n",
    "and lo_suppkey = s_suppkey\n",
    "and lo_orderdate = d_datekey\n",
    "and (c_city='UNITED KI1' or\n",
    "c_city='UNITED KI5')\n",
    "and (s_city='UNITED KI1' or\n",
    "s_city='UNITED KI5')\n",
    "and d_yearmonth = 'Dec1997'\n",
    "group by c_city, s_city, d_year\n",
    "order by d_year asc, revenue desc;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "oneDimSameDist_SQL =\"\"\"\n",
    "set enable_result_cache_for_session to off;\n",
    "SET search_path TO {};\n",
    "\n",
    "select lo_orderdate, sum(lo_extendedprice*lo_discount) as revenue  \n",
    "from lineorder, part\n",
    "where lo_partkey  = p_partkey\n",
    "group by lo_orderdate\n",
    "order by lo_orderdate\n",
    "\"\"\"\n",
    "\n",
    "def compareQueryTimes(schema):\n",
    "    queryTimes  =[] \n",
    "    for i,query in enumerate([oneDim_SQL, twoDim_SQL, drill_SQL, oneDimSameDist_SQL]):\n",
    "        t0 = time()\n",
    "        q = query.format(schema)\n",
    "        %sql $q\n",
    "        queryTime = time()-t0\n",
    "        queryTimes.append(queryTime)\n",
    "    return pd.DataFrame({\"query\":[\"oneDim\",\"twoDim\", \"drill\", \"oneDimSameDist\"], \"queryTime_\"+schema:queryTimes}).set_index('query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noDistQueryTimes = compareQueryTimes(\"nodist\")\n",
    "distQueryTimes   = compareQueryTimes(\"dist\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryTimeDF =noDistQueryTimes.join(distQueryTimes)\n",
    "queryTimeDF.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvementDF = queryTimeDF[\"distImprovement\"] =100.0*(queryTimeDF['queryTime_nodist']-queryTimeDF['queryTime_dist'])/queryTimeDF['queryTime_nodist']\n",
    "improvementDF.plot.bar(title=\"% dist Improvement by query\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
